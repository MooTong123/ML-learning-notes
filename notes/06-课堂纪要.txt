2.6 api介绍【**】
    1.梯度下降法
        sklearn.linear_model.SGDRegressor(loss="squared_loss", fit_intercept=True, learning_rate ='invscaling', eta0=0.01)
            参数：
                1.loss -- 损失 （最小二乘）
                2.learning_rate -- 学习率
                    一般时都是进行动态的更新，也可以指定成为一个常数，但是不推荐。
2.8 欠拟合和过拟合【****】
    欠拟合
        在训练集上表现不好，在测试集上表现不好
        解决方法：
            继续学习
            1.添加其他特征项
            2.添加多项式特征
    过拟合
        在训练集上表现好，在测试集上表现不好
        解决方法：
            1.重新清洗数据集
            2.增大数据的训练量
            3.正则化
            4.减少特征维度
    正则化
        通过限制高次项的系数进行防止过拟合
            L1正则化
                理解：直接把高次项前面的系数变为0
                Lasso回归
            L2正则化
                理解：把高次项前面的系数变成特别小的值
                岭回归
2.9  正则化线性模型【***】
    1.Ridge Regression 岭回归
        就是把系数添加平方项
        然后限制系数值的大小
        α值越小，系数值越大，α越大，系数值越小
    2.Lasso 回归
        对系数值进行绝对值处理
        由于绝对值在顶点处不可导，所以进行计算的过程中产生很多0，最后得到结果为：稀疏矩阵
    3.Elastic Net 弹性网络
        是前两个内容的综合
        设置了一个r,如果r=0--岭回归；r=1--Lasso回归
    4.Early stopping
        通过限制错误率的阈值，进行停止
2.10 线性回归的改进-岭回归【**】
    1.api
    sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True,solver="auto", normalize=False)
        具有l2正则化的线性回归
        alpha -- 正则化
            正则化力度越大，权重系数会越小
            正则化力度越小，权重系数会越大
        normalize
            默认封装了，对数据进行标准化处理
2.11 模型的保存和加载【*】
    api:
    sklearn.externals import joblib
        保存：joblib.dump(estimator, 'test.pkl')
        加载：estimator = joblib.load('test.pkl')
    注意：
    1.保存文件，后缀名是**.pkl
    2.加载模型是需要通过一个变量进行承接

3.逻辑回归
3.1 逻辑回归介绍【****】
    1.逻辑回归概念
        解决的是一个二分类问题
        逻辑回归的输入是线性回归的输出
    2.原理
        1.输入：
            线性回归的输出
        2.激活函数
            sigmoid函数
                把整体的值映射到[0,1]
                再设置一个阈值，进行分类判断
        3.损失
            对数似然损失
                借助了log思想，进行完成
                真实值等于0，等于1两种情况进行划分
        4.优化
            提升原本属于1类别的概率，降低原本是0类别的概率。
3.2 逻辑回归api介绍【*】
    sklearn.linear_model.LogisticRegression()
    注意：回归，分类api有时候是可以混合使用的
3.3 案例：癌症分类预测-良／恶性乳腺癌肿瘤预测【**】
    1.获取数据
    2.基本数据处理
    2.1 缺失值处理
    2.2 确定特征值,目标值
    2.3 分割数据
    3.特征工程(标准化)
    4.机器学习(逻辑回归)
    5.模型评估
3.4 分类评估方法【***】
    1.混淆矩阵
        真正例（TP）
        伪反例（FN）
        伪正例（FP）
        真反例（TN）
    2. 精确率(Precision)与召回率(Recall)
        准确率：（对不对）
            （TP+TN）/(TP+TN+FN+FP)
        精确率 -- 查的准不准
            TP/(TP+FP)
        召回率 -- 查的全不全
            TP/(TP+FN)
        F1-score
            反映模型的稳健性
    3.api
        sklearn.metrics.classification_report(y_true, y_pred)
    4.roc曲线和auc指标
        roc曲线
            通过tpr和fpr来进行图形绘制，然后绘制之后，行成一个指标auc
        auc
            越接近1，效果越好
            越接近0，效果越差
            越接近0.5，效果就是胡说
        注意：
            这个指标主要用于评价不平衡的二分类问题
    5.api
        sklearn.metrics.roc_auc_score(y_true, y_score)
            y_true -- 要把正例转换为1，反例转换为0
3.5 ROC曲线的绘制【###】
    1.构建模型，把模型的概率值从大到小进行排序
    2.从概率最大的点开始取值，一直进行tpr和fpr的计算，然后构建整体模型，得到结果
    3.其实就是在求解积分（面积）

4.决策树算法
4.1 决策树算法简介【**】
    1.简介
        定义：
        是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果，本质是一颗由多个判断节点组成的树
4.2 决策树分类原理【****】
    1.熵
        用于衡量一个对象的有序程度
        系统越有序，熵值越低；系统越混乱或者分散，熵值越高。
    2.信息熵
        1.从信息的完整性上进行的描述:
        当系统的有序状态一致时，数据越集中的地方熵值越小，数据越分散的地方熵值越大。
        2.从信息的有序性上进行的描述:
        当数据量一致时，系统越有序，熵值越低；系统越混乱或者分散，熵值越高。
    3.把信息转换成熵值
        -plogp

